<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Length-Agnostic Open-Vocab Video Amodal Completion via Diffusion Models with Text and Optical Flow Guidance.">
  <meta name="keywords" content="video amodal completion, amodal completion, diffusion models, optical flow, text guidance, open-vocabulary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LANCOF: Length-Agnostic Open-Vocab Video Amodal Completion</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Length-Agnostic Open-Vocab Video Amodal Completion via Diffusion Models with Text and Optical Flow Guidance</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Minh Tran,&nbsp;</span>
            <span class="author-block">Winston Bounsavy,&nbsp;</span>
            <span class="author-block">Taisei Hanyu,&nbsp;</span>
            <span class="author-block">Thang Pham,&nbsp;</span>
            <span class="author-block">Ngan Le</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">AICV Lab, Department of EECS, University of Arkansas</span>
          </div>

          <strong class="is-size-5" style="color:#3e8ed0;">Preprint</strong>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Update these links when available. -->
              <span class="link-block">
                <a href="./static/paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (PDF)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#BibTeX"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-quote-right"></i>
                  </span>
                  <span>BibTeX</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#teaser"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-play"></i>
                  </span>
                  <span>Teaser</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   aria-disabled="true"
                   style="pointer-events: none; opacity: 0.65;"
                   title="Update this link to point to your code repository."
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (TBD)</span>
                  </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" id="teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaserVideo" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle">
        <strong>LANCOF</strong> performs video amodal completion (masks + appearance) under heavy occlusion and supports arbitrary video lengths via a zero-shot temporal generation pipeline.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Amodal perception enables humans to perceive entire objects even when parts are occluded, a remarkable cognitive skill that artificial intelligence struggles to replicate.
            Substantial advancements have been made in image amodal completion and are now being extended to the video domain thanks to rapid progress in diffusion models for visual synthesis.
            While recent advances in video amodal completion show promise, existing approaches suffer from two critical limitations: insufficient auxiliary information to guide recovery of heavily occluded content, and inability to handle videos of arbitrary length.
            We present <strong>LANCOF</strong> (Length-Agnostic Video Amodal Completion via Diffusion Model with Text and Optical Flow Guidance), which addresses these limitations through complementary prior knowledge.
            Our approach uses optical flow as motion priors for consistent mask completion and text guidance as semantic priors for accurate content reconstruction.
            A zero-shot generation pipeline with a Temporal Generation module and anchor-frame attention enables truly length-agnostic processing without duration-specific training.
            We also contribute <strong>LAVAT</strong>, a comprehensive dataset with long video sequences and text descriptions as prior knowledge for heavy occlusion cases.
            Extensive experiments show LANCOF achieves state-of-the-art performance on existing benchmarks while demonstrating superior generalization to longer sequences, advancing both training capabilities and evaluation standards for video amodal completion.
          </p>
        </div>
        <div class="content has-text-left">
          <ul>
            <li><strong>Optical-flow guidance</strong> as motion priors for mask completion.</li>
            <li><strong>Text guidance</strong> as semantic priors for appearance completion.</li>
            <li><strong>Length-agnostic</strong> zero-shot temporal generation for arbitrary durations.</li>
            <li><strong>LAVAT benchmark</strong> with long sequences and text descriptions.</li>
          </ul>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Method Overview</h2>
          <p>LANCOF performs (1) mask completion guided by optical flow and (2) appearance completion guided by text, with a zero-shot temporal generation pipeline for arbitrary video lengths.</p>
          <img src="./static/images/lancof/pipeline.png" alt="LANCOF pipeline overview">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">LAVAT Benchmark</h2>
          <p>We introduce <strong>LAVAT</strong>, a benchmark with long video sequences and text descriptions to evaluate amodal completion under heavy occlusion and long-term temporal consistency.</p>
          <img src="./static/images/lancof/dataset_creation.png" alt="LAVAT dataset creation overview">
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Dataset Statistics</h2>
          <div class="columns is-variable is-4 is-multiline">
            <div class="column is-half">
              <img src="./static/images/lancof/lavat_chart1_length_compare.png" alt="Length comparison chart">
            </div>
            <div class="column is-half">
              <img src="./static/images/lancof/lavat_chart2_occlusion_hist.png" alt="Occlusion histogram">
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Qualitative Results</h2>
          <p>Examples on in-the-wild videos and benchmarks.</p>
          <img src="./static/images/lancof/quali_result_itw.png" alt="In-the-wild qualitative results">
          <img src="./static/images/lancof/quali_results_lavat.png" alt="Qualitative results on LAVAT">
          <img src="./static/images/lancof/quali_results_taco.png" alt="Qualitative results on TACO">
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{tran2026lancof,
  title={Length-Agnostic Open-Vocab Video Amodal Completion via Diffusion Models with Text and Optical Flow Guidance},
  author={Minh Tran and Winston Bounsavy and Taisei Hanyu and Thang Pham and Ngan Le},
  year={2026},
  note={Preprint}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content" style="text-align: center;">
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We sincerely thank them for this excellent open-source template!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
